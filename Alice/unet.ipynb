from torch.utils.data import DataLoader
from tqdm.notebook import tqdm
from pathlib import Path

import torch.optim as optim
import pandas as pd
import torch.nn as nn
import torch

import os

from data_loader import BraTSDataset
from unet import Unet
from train_step import train_step

import warnings
warnings.filterwarnings("ignore")

data_folder = Path('/Users/alisakugusheva/Desktop/HSE/Project/brats_slices_2/')
df_folder = Path('/Users/alisakugusheva/Desktop/HSE/Project')
df = pd.read_csv(df_folder / 'meta.csv', index_col=0)

df = df.sort_values(by=['subject_id'], ignore_index=True)

train_size = int(0.8 * df.shape[0])
val_size = df.shape[0] - train_size

border_id = df['subject_id'][train_size]

train_df = df[df['subject_id'] < border_id]
val_df = df[df['subject_id'] >= border_id]

train_dataset = BraTSDataset(train_df, data_folder, nonzero_mask=True)
val_dataset = BraTSDataset(val_df, data_folder, nonzero_mask=True)


train_loader = torch.utils.data.DataLoader(train_dataset,
                                             batch_size=128, shuffle=True,
                                             num_workers=2)
val_loader = torch.utils.data.DataLoader(val_dataset,
                                             batch_size=128, shuffle=False,
                                             num_workers=2)

device = ("cuda" if torch.cuda.is_available() else 'cpu')
model = Unet().to(device)

criterion = nn.BCEWithLogitsLoss() 
optimizer = optim.Adam(model.parameters(), lr=0.001)

for epoch in range(5):
    epoch_loss = 0
    for X_batch, y_batch in tqdm(train_loader):

        loss = train_step(X_batch, y_batch, model, criterion, optimizer)
        
        epoch_loss += loss     

    print(f'Epoch {epoch+0:03}: | Loss: {epoch_loss/len(train_loader):.5f}')

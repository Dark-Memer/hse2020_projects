{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Plan\n",
    "\n",
    "Задача: бинарная сегментация\n",
    "\n",
    "На вход двумерное одноканальное (grayscale) изображение, на выходе бинарная маска.\n",
    "\n",
    "Про отключение dropout/batch normalization для инференса https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prettify data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, source_folder: [str, Path], transform=None):\n",
    "        if isinstance(source_folder, str):\n",
    "            source_folder = Path(source_folder)\n",
    "            \n",
    "        self.images = sorted(list(source_folder.glob('*')))\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.images)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        \n",
    "        file_name = self.images[i].stem.split('_')[-1]\n",
    "        slices = list(self.images[i].glob('*'))\n",
    "        slices = [s.stem for s in slices if 'mask' not in s.stem]\n",
    "        np.random.shuffle(slices)\n",
    "        j = slices[0]\n",
    "        \n",
    "        image = np.load(self.images[i] / f'{j}.npy', allow_pickle=True)\n",
    "        mask = np.load(self.images[i] / f'{j}_mask.npy', allow_pickle=True)\n",
    "        sample = image, mask\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('/home/anvar/work/data/brats_slices/')\n",
    "data = BraTSDataset(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "370"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.92 ms ± 114 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "data[100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a csv file with important metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_folder = Path('/home/anvar/work/data/brats_slices/')\n",
    "# df = []\n",
    "\n",
    "# for path, _, files in tqdm(os.walk(data_folder)):\n",
    "#     for file in files:\n",
    "        \n",
    "#         subject_id = path.split('/')[-1].split('_')[-1]\n",
    "#         slice_id = file.split('.')[0].split('_')[0]\n",
    "#         sample_id = f\"{subject_id}_{slice_id}\" # SubjectID_SliceIndex\n",
    "#         is_mask = 'mask' in file\n",
    "#         if is_mask:\n",
    "#             mask = np.load(Path(path) / file, allow_pickle=True)\n",
    "#             is_nonzero_mask =  np.any(mask)\n",
    "#         else:\n",
    "#             is_nonzero_mask = np.nan\n",
    "        \n",
    "#         df.append([Path(Path(path).stem) / file, sample_id, is_mask, subject_id, is_nonzero_mask])\n",
    "        \n",
    "# df = pd.DataFrame(df, columns = ['relative_path', 'sample_id', 'is_mask', 'subject_id', 'is_nonzero_mask'])\n",
    "# print(df.is_nonzero_mask.value_counts())\n",
    "\n",
    "# df.to_csv(data_folder / 'meta.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Важное преимущество такого метода в том что вы убираете из класса описывающего ваш датасет\n",
    "низкоуровневую работу со структурой ваших папок на диске, у вас просто есть таблица, в которой для каждого\n",
    "файла указан путь к нему, и набор его id полей (например номер слайса и номер пациента, но могут быть и другие поля)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(data_folder / 'meta.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>relative_path</th>\n",
       "      <th>sample_id</th>\n",
       "      <th>is_mask</th>\n",
       "      <th>subject_id</th>\n",
       "      <th>is_nonzero_mask</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BraTS20_Training_274/25.npy</td>\n",
       "      <td>274_25</td>\n",
       "      <td>False</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BraTS20_Training_274/71_mask.npy</td>\n",
       "      <td>274_71</td>\n",
       "      <td>True</td>\n",
       "      <td>274</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BraTS20_Training_274/35_mask.npy</td>\n",
       "      <td>274_35</td>\n",
       "      <td>True</td>\n",
       "      <td>274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BraTS20_Training_274/46.npy</td>\n",
       "      <td>274_46</td>\n",
       "      <td>False</td>\n",
       "      <td>274</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BraTS20_Training_274/3_mask.npy</td>\n",
       "      <td>274_3</td>\n",
       "      <td>True</td>\n",
       "      <td>274</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      relative_path sample_id  is_mask  subject_id  \\\n",
       "0       BraTS20_Training_274/25.npy    274_25    False         274   \n",
       "1  BraTS20_Training_274/71_mask.npy    274_71     True         274   \n",
       "2  BraTS20_Training_274/35_mask.npy    274_35     True         274   \n",
       "3       BraTS20_Training_274/46.npy    274_46    False         274   \n",
       "4   BraTS20_Training_274/3_mask.npy     274_3     True         274   \n",
       "\n",
       "  is_nonzero_mask  \n",
       "0             NaN  \n",
       "1            True  \n",
       "2           False  \n",
       "3             NaN  \n",
       "4           False  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(101688, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Edit BratSDataset class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BraTSDataset(Dataset):\n",
    "    def __init__(self, meta: pd.DataFrame, source_folder: [str, Path], transform=None):\n",
    "        if isinstance(source_folder, str):\n",
    "            source_folder = Path(source_folder)\n",
    "            \n",
    "        self.source_folder = source_folder\n",
    "        self.meta_images = meta.query('is_mask == False').sort_values(by='sample_id').reset_index(drop=True)\n",
    "        self.meta_masks = meta.query('is_mask == True').sort_values(by='sample_id').reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.meta_images.shape[0]\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        image = np.load(self.source_folder / self.meta_images.iloc[i]['relative_path'], allow_pickle=True)\n",
    "        mask = np.load(self.source_folder / self.meta_masks.iloc[i]['relative_path'], allow_pickle=True)\n",
    "        sample = image, mask\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = Path('/home/anvar/work/data/brats_slices/')\n",
    "data = BraTSDataset(df, data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50844"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.6 ms ± 66 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit\n",
    "\n",
    "data[20000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.10162"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "50844 * 1.3 / 1000 / 60"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "300"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1 * 300"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Define Unet architecture\n",
    "\n",
    "https://arxiv.org/abs/1505.04597\n",
    "\n",
    "![title](https://lmb.informatik.uni-freiburg.de/people/ronneber/u-net/u-net-architecture.png)\n",
    "\n",
    "\n",
    "с одним изменением, вместо кропов будем интерполировать (чтобы в результате на выходе получить маску того же размера что и вход)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv_3x3(in_c, out_c):\n",
    "    return nn.Sequential(\n",
    "                nn.Conv2d(in_c, out_c, kernel_size=3),\n",
    "                nn.ReLU(inplace=True),\n",
    "                nn.Conv2d(out_c, out_c, kernel_size=3),\n",
    "                nn.ReLU(inplace=True)\n",
    "    )\n",
    "\n",
    "class Unet(nn.Module):\n",
    "    \n",
    "    def __init__(self, ):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.max_pool2x2 = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "        self.down_conv_1 = conv_3x3(1, 64)\n",
    "        self.down_conv_2 = conv_3x3(64, 128)\n",
    "        self.down_conv_3 = conv_3x3(128, 256)\n",
    "        self.down_conv_4 = conv_3x3(256, 512)\n",
    "        self.down_conv_5 = conv_3x3(512, 1024)\n",
    "        \n",
    "        self.up_transp_conv_1 = nn.ConvTranspose2d(1024, 512, kernel_size=2, stride=2)\n",
    "        self.upsample_1 = nn.Upsample(64, mode='bilinear')\n",
    "        self.up_conv_1 = conv_3x3(1024, 512)\n",
    "        \n",
    "        self.up_transp_conv_2 = nn.ConvTranspose2d(512, 256, kernel_size=2, stride=2)\n",
    "        self.up_conv_2 = conv_3x3(512, 256)\n",
    "        self.upsample_2 = nn.Upsample(136, mode='bilinear')\n",
    "        \n",
    "        self.up_transp_conv_3 = nn.ConvTranspose2d(256, 128, kernel_size=2, stride=2)\n",
    "        self.up_conv_3 = conv_3x3(256, 128)\n",
    "        self.upsample_3 = nn.Upsample(280, mode='bilinear')\n",
    "        \n",
    "        self.up_transp_conv_4 = nn.ConvTranspose2d(128, 64, kernel_size=2, stride=2)\n",
    "        self.up_conv_4 = conv_3x3(128, 64)\n",
    "        self.upsample_4 = nn.Upsample(568, mode='bilinear')\n",
    "        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x1 = self.down_conv_1(x) #+\n",
    "        x2 = self.max_pool2x2(x1) \n",
    "        \n",
    "        x3 = self.down_conv_2(x2) #+\n",
    "        print(x3.shape)\n",
    "        x4 = self.max_pool2x2(x3) \n",
    "        \n",
    "        x5 = self.down_conv_3(x4) #+\n",
    "        x6 = self.max_pool2x2(x5) \n",
    "        \n",
    "        x7 = self.down_conv_4(x6) #+\n",
    "        x8 = self.max_pool2x2(x7) \n",
    "\n",
    "        x9 = self.down_conv_5(x8) \n",
    "    \n",
    "        x = self.up_transp_conv_1(x9)\n",
    "        x = self.up_conv_1(torch.cat([self.upsample_1(x), x7], axis=1))\n",
    "        \n",
    "        x = self.up_transp_conv_2(x)\n",
    "        x = self.up_conv_2(torch.cat([self.upsample_2(x), x5], axis=1))\n",
    "        \n",
    "        x = self.up_transp_conv_3(x)\n",
    "        x = self.up_conv_3(torch.cat([self.upsample_3(x), x3], axis=1))\n",
    "        \n",
    "        x = self.up_transp_conv_4(x)\n",
    "        x = self.up_conv_4(torch.cat([self.upsample_4(x), x1], axis=1))\n",
    "        \n",
    "        print(x.shape)\n",
    "#         return x5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Unet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(1, 1, 572, 572)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 128, 280, 280])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/anvar/anaconda3/lib/python3.8/site-packages/torch/nn/functional.py:3060: UserWarning: Default upsampling behavior when mode=bilinear is changed to align_corners=False since 0.4.0. Please specify align_corners=True if the old behavior is desired. See the documentation of nn.Upsample for details.\n",
      "  warnings.warn(\"Default upsampling behavior when mode={} is changed \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 564, 564])\n"
     ]
    }
   ],
   "source": [
    "_ = model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "conv = nn.Conv2d(64, 128, kernel_size=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 3, 3])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones = torch.ones(1, 2, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.6093, -0.6093, -0.6093],\n",
       "          [-0.6093, -0.6093, -0.6093],\n",
       "          [-0.6093, -0.6093, -0.6093]],\n",
       "\n",
       "         [[ 0.2575,  0.2575,  0.2575],\n",
       "          [ 0.2575,  0.2575,  0.2575],\n",
       "          [ 0.2575,  0.2575,  0.2575]]]], grad_fn=<ThnnConv2DBackward>)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv(ones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 64, 3, 3])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conv.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "ones2 = torch.ones(1,2,5,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Given groups=1, weight of size [2, 1, 3, 3], expected input[1, 2, 5, 5] to have 1 channels, but got 2 channels instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-31-103b6052b39b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mones2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    725\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 727\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    728\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    729\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 423\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_conv_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    424\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    425\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0mConv3d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ConvNd\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36m_conv_forward\u001b[0;34m(self, input, weight)\u001b[0m\n\u001b[1;32m    417\u001b[0m                             \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstride\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m                             _pair(0), self.dilation, self.groups)\n\u001b[0;32m--> 419\u001b[0;31m         return F.conv2d(input, weight, self.bias, self.stride,\n\u001b[0m\u001b[1;32m    420\u001b[0m                         self.padding, self.dilation, self.groups)\n\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Given groups=1, weight of size [2, 1, 3, 3], expected input[1, 2, 5, 5] to have 1 channels, but got 2 channels instead"
     ]
    }
   ],
   "source": [
    "conv(ones2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
